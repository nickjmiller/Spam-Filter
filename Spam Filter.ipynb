{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Classifier on Fake Reviews\n",
    "How to create and train a classifier to spot fake reviews on Yelp, using supervised learning and the Natural Language Toolkit (NLTK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sqlite3\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are contained in a database, there are 750,000 reviews in total, but we will only be sampling 20,000 entries.\n",
    "\n",
    "Our first step will be to extract these reviews from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('yelpHotelData.db')\n",
    "c = conn.cursor()\n",
    "fake = []\n",
    "real = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in c.execute(\n",
    "    'SELECT reviewContent, rating, usefulCount, coolCount, funnyCount FROM review WHERE flagged = \"Y\" OR flagged = \"YR\" '):\n",
    "    fake.append([nltk.word_tokenize(row[0]), row[1], row[2], row[3], row[4],'fake'])\n",
    "random.shuffle(fake)\n",
    "fake = fake[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in c.execute('SELECT reviewContent, rating, usefulCount, coolCount, funnyCount FROM review WHERE flagged = \"N\" OR flagged = \"NR\" '):\n",
    "    real.append([nltk.word_tokenize(row[0]), row[1], row[2], row[3], row[4],'real'])\n",
    "random.shuffle(real)\n",
    "real = real[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to combine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = real + fake\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common strategy for semantice analysis is to look at whether or not a word appears in the text. While it would be impossible to have a separate feature for every word, we can grab the 2000 most common words and turn them into features. First we will pull these words and create a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(word.lower() for (doc,rt,use,cool,fun,tg) in documents for word in doc)\n",
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The feature extractor\n",
    "We have the data, and we have some word features we want to check. The next step is to construct a feature extractor that can pull the features from each document. We will construct a function that checks if each word in the set of 2000 words appears in the review. Each of these checks is actually a binary feature, so we will end up having 2000+ features for each review. We will also grab some other useful features, such as..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(doc,rt,use,cool,fun):\n",
    "    document_words = set(doc)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains ' + word] = (word in document_words)\n",
    "    features.update({'rating': rt, 'useful': use, 'cool': cool, 'funny': fun, 'length': len(doc)})\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the feature extractor, it's time to extract those features and create test and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d,rt,use,cool,fun), c) for (d,rt,use,cool,fun,c) in documents]\n",
    "train_set, test_set = featuresets[2000:], featuresets[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "NLTK comes with a few built-in classifiers, we will first try the naive bayes classifier. This is a good classifier for our data since it is fast, we have a huge dataset with a lot of features so this is a very good quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554\n",
      "Most Informative Features\n",
      "           contains yoga = True             real : fake   =     13.3 : 1.0\n",
      "      contains newspaper = True             real : fake   =      6.5 : 1.0\n",
      "         contains nicest = True             real : fake   =      6.0 : 1.0\n",
      "                  length = 340              real : fake   =      5.8 : 1.0\n",
      "                  length = 220              fake : real   =      5.5 : 1.0\n",
      "   contains overpowering = True             fake : real   =      5.2 : 1.0\n",
      "       contains research = True             real : fake   =      5.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
